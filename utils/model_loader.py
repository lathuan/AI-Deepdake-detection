# utils/model_loader.py
import torch
import torch.nn as nn
import torchvision.models as models
import os

class ImprovedDeepfakeClassifier(nn.Module):
    def __init__(self, num_frames=20, num_classes=1):
        super(ImprovedDeepfakeClassifier, self).__init__()
        
        resnet = models.resnet18(pretrained=False)
        self.cnn_backbone = nn.Sequential(*list(resnet.children())[:-1])
        
        self.lstm = nn.LSTM(512, 128, batch_first=True, bidirectional=True, dropout=0.3)
        self.classifier = nn.Sequential(
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(64, num_classes)
        )
        
    def forward(self, x):
        batch_size, num_frames, C, H, W = x.shape
        cnn_features = []
        
        for i in range(num_frames):
            frame = x[:, i, :, :, :]
            features = self.cnn_backbone(frame)
            features = features.view(batch_size, -1)
            cnn_features.append(features)
        
        cnn_features = torch.stack(cnn_features, dim=1)
        lstm_out, _ = self.lstm(cnn_features)
        output = self.classifier(lstm_out[:, -1, :])
        return output

def load_trained_model(model_path, device='auto'):
    """
    Load model ƒë√£ train t·ª´ file .pth
    
    Args:
        model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file model
        device: 'auto', 'cuda', ho·∫∑c 'cpu'
    
    Returns:
        model: Model ƒë√£ ƒë∆∞·ª£c load weights
    """
    if device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # Ki·ªÉm tra file model c√≥ t·ªìn t·∫°i kh√¥ng
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file model: {model_path}")
    
    # Kh·ªüi t·∫°o model
    model = ImprovedDeepfakeClassifier()
    
    # Load weights
    checkpoint = torch.load(model_path, map_location=device)
    
    # X·ª≠ l√Ω c√°c ƒë·ªãnh d·∫°ng checkpoint kh√°c nhau
    if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint
    
    # Load state dict
    model.load_state_dict(state_dict)
    model.to(device)
    model.eval()
    
    print(f"‚úÖ ƒê√£ load model t·ª´: {model_path}")
    print(f"üñ•Ô∏è Device: {device}")
    
    return model, device