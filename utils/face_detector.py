# utils/face_detector.py
from ultralytics import YOLO
import cv2
import os

class FaceDetector:
    def __init__(self, model_path='yolov8l-face-lindevs.pt'): 
        """
        Kh·ªüi t·∫°o face detector v·ªõi YOLO
        
        Args:
            model_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn model YOLO custom
        """
        # Ki·ªÉm tra xem file model c√≥ t·ªìn t·∫°i kh√¥ng
        if not os.path.exists(model_path):
            print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y model: {model_path}")
            print("üì• ƒêang t·∫£i model m·∫∑c ƒë·ªãnh...")
            model_path = 'yolov8l-face-lindevs.pt'
        
        try:
            self.model = YOLO(model_path)
            print(f"‚úÖ ƒê√£ load face detection model: {os.path.basename(model_path)}")
        except Exception as e:
            print(f"‚ùå L·ªói khi load model {model_path}: {e}")
            print("üîÑ ƒêang th·ª≠ load model m·∫∑c ƒë·ªãnh...")
            self.model = YOLO('yolov8l-face-lindevs.pt')
        
    def extract_faces_from_video(self, video_path, max_frames=20, conf_threshold=0.7):
        """
        Tr√≠ch xu·∫•t khu√¥n m·∫∑t t·ª´ video
        
        Args:
            video_path: ƒê∆∞·ªùng d·∫´n video
            max_frames: S·ªë frame t·ªëi ƒëa
            conf_threshold: Ng∆∞·ª°ng confidence
            
        Returns:
            List c√°c khu√¥n m·∫∑t ƒë√£ c·∫Øt
        """
        try:
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                print(f"‚ùå Kh√¥ng th·ªÉ m·ªü video: {video_path}")
                return []
            
            face_frames = []
            frame_count = 0
            max_frames_to_process = 100
            
            while len(face_frames) < max_frames and frame_count < max_frames_to_process:
                ret, frame = cap.read()
                if not ret:
                    break
                    
                frame_count += 1
                
                # X·ª≠ l√Ω m·ªói 5 frame ƒë·ªÉ ti·∫øt ki·ªám th·ªùi gian
                if frame_count % 5 != 0:
                    continue
                
                # Chuy·ªÉn BGR sang RGB
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # Ph√°t hi·ªán khu√¥n m·∫∑t v·ªõi YOLO
                results = self.model(frame_rgb, conf=conf_threshold, verbose=False)
                
                for result in results:
                    if len(result.boxes) > 0:
                        for box in result.boxes:
                            confidence = box.conf[0].item()
                            if confidence > conf_threshold:
                                # L·∫•y t·ªça ƒë·ªô bounding box
                                x1, y1, x2, y2 = map(int, box.xyxy[0])
                                
                                # Th√™m padding
                                padding = 20
                                h, w = frame.shape[:2]
                                x1 = max(0, x1 - padding)
                                y1 = max(0, y1 - padding)
                                x2 = min(w, x2 + padding)
                                y2 = min(h, y2 + padding)
                                
                                # C·∫Øt khu√¥n m·∫∑t
                                face = frame[y1:y2, x1:x2]
                                
                                if face.size > 0:
                                    face_frames.append(face)
            
            cap.release()
            
            if len(face_frames) == 0:
                print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong video")
            
            return face_frames
            
        except Exception as e:
            print(f"‚ùå L·ªói khi x·ª≠ l√Ω video: {e}")
            return []
        