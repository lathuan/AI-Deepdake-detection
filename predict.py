# predict.py
import uuid
import os
import argparse
import cv2
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
from utils.model_loader import load_trained_model
from utils.face_detector import FaceDetector
from utils.video_processor import VideoProcessor

def create_confidence_timeline(time_confidence_data,overall_prediction):
    """Táº¡o biá»ƒu Ä‘á»“ confidence theo thá»i gian"""
    plt.figure(figsize=(12, 4))
    
    times = [data['time_sec'] for data in time_confidence_data]
    confidences = [data['confidence'] for data in time_confidence_data]
    
    plt.plot(times, confidences, 'b-', alpha=0.7, linewidth=2, label='Confidence FAKE')
    plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='NgÆ°á»¡ng FAKE/REAL')
    plt.fill_between(times, confidences, 0.5, where=np.array(confidences)>0.5, 
                     alpha=0.3, color='red', label='VÃ¹ng nghi ngá» FAKE')
    plt.fill_between(times, confidences, 0.5, where=np.array(confidences)<=0.5, 
                     alpha=0.3, color='green', label='VÃ¹ng an toÃ n')
    
    plt.xlabel('Thá»i gian (giÃ¢y)')
    plt.ylabel('Confidence FAKE')
    plt.title('BIá»‚U Äá»’ CONFIDENCE THEO THá»œI GIAN')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)
    return plt

def predict_deepfake(video_path, model_path='best_deepfake_model_dfd.pth', device='auto'):
    """HÃ m dá»± Ä‘oÃ¡n Ä‘á»ƒ gá»i tá»« Flask"""
    try:
        if not os.path.exists(video_path):
            return {"error": "Video file not found"}

        model, device = load_trained_model(model_path, device)
        face_detector = FaceDetector()
        video_processor = VideoProcessor(face_detector)

        result = video_processor.predict_video_detailed(video_path, model, device)

        # Chuáº©n bá»‹ frame + heatmap cho web
        frames_for_web = []
        if "frame_analysis" in result and result["frame_analysis"]:
            for frame_info in result["frame_analysis"]:
                face_rgb = frame_info['face_image'][..., ::-1]  # BGR->RGB
                pil_face = Image.fromarray(face_rgb)
                pil_heatmap = None
                if 'heatmap_overlay' in frame_info:
                    heatmap_rgb = frame_info['heatmap_overlay'][..., ::-1]
                    pil_heatmap = Image.fromarray(heatmap_rgb)

                frames_for_web.append({
                    "frame_index": frame_info['frame_index'],
                    "confidence": frame_info['confidence'],
                    "is_suspicious": frame_info['is_suspicious'],
                    "face_image": pil_face,
                    "heatmap_overlay": pil_heatmap
                })
        result['frames_for_web'] = frames_for_web
        return result

    except Exception as e:
        return {"error": f"Prediction error: {str(e)}"}

def display_advanced_result(video_path, result):
    """Hiá»ƒn thá»‹ káº¿t quáº£ phÃ¢n tÃ­ch nÃ¢ng cao"""
    color = 'red' if result['prediction'] == 'FAKE' else 'green'
    emoji = 'âŒ' if result['prediction'] == 'FAKE' else 'âœ…'
    
    print(f"\n{'='*80}")
    print(f"{emoji} PHÃ‚N TÃCH DEEPFAKE CHI TIáº¾T {emoji}")
    print(f"{'='*80}")
    print(f"ğŸ“¹ Video: {os.path.basename(video_path)}")
    print(f"ğŸ¯ Káº¾T QUáº¢: {result['prediction']}")
    print(f"ğŸ“Š Äá»™ tin cáº­y tá»•ng: {result['confidence']:.1%}")
    print(f"ğŸ”¢ XÃ¡c suáº¥t FAKE: {result['probability']:.4f}")
    print(f"ğŸ‘¤ Sá»‘ frames phÃ¢n tÃ­ch: {result['num_faces']}")
    
    # Hiá»ƒn thá»‹ cÃ¡c frame nghi ngá» nháº¥t
    if result['frame_analysis']:
        print(f"\nğŸ” {len(result['frame_analysis'])} FRAME NGHI NGá»œ NHáº¤T:")
        
        # Táº¡o subplot cho cÃ¡c frame nghi ngá»
        num_frames = len(result['frame_analysis'])
        fig, axes = plt.subplots(2, num_frames, figsize=(20, 8))
        
        if num_frames == 1:
            axes = axes.reshape(2, 1)
        
        for i, frame_info in enumerate(result['frame_analysis']):
            # HÃ ng 1: áº¢nh gá»‘c vá»›i bounding box
            face_rgb = cv2.cvtColor(frame_info['face_image'], cv2.COLOR_BGR2RGB)
            axes[0, i].imshow(face_rgb)
            axes[0, i].set_title(f'Frame {frame_info["frame_index"]}\nConf: {frame_info["confidence"]:.3f}', 
                               color='red' if frame_info['is_suspicious'] else 'green',
                               fontweight='bold')
            axes[0, i].axis('off')
            
            # HÃ ng 2: Heatmap overlay
            if 'heatmap_overlay' in frame_info:
                heatmap_rgb = cv2.cvtColor(frame_info['heatmap_overlay'], cv2.COLOR_BGR2RGB)
                axes[1, i].imshow(heatmap_rgb)
                axes[1, i].set_title('Heatmap\n(VÃ¹ng AI chÃº Ã½)', fontsize=10)
                axes[1, i].axis('off')
            
            # ThÃªm bounding box mÃ u theo má»©c Ä‘á»™ nghi ngá»
            for spine in axes[0, i].spines.values():
                spine.set_edgecolor('red' if frame_info['is_suspicious'] else 'green')
                spine.set_linewidth(3)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.85)
        plt.suptitle('CÃC FRAME NGHI NGá»œ NHáº¤T VÃ€ HEATMAP PHÃ‚N TÃCH', 
                    fontsize=14, color=color, fontweight='bold')
        plt.show()
    
    # Hiá»ƒn thá»‹ biá»ƒu Ä‘á»“ timeline
    if result['time_confidence_data']:
        timeline_plot = create_confidence_timeline(result['time_confidence_data'], result['prediction'])
        timeline_plot.show()
    
    # Thá»‘ng kÃª chi tiáº¿t
    print(f"\nğŸ“ˆ THá»NG KÃŠ PHÃ‚N TÃCH:")
    all_confs = result['all_frame_confidences']
    suspicious_frames = sum(1 for conf in all_confs if conf > 0.5)
    avg_confidence = np.mean(all_confs)
    max_confidence = max(all_confs)
    
    print(f"   - Frames nghi ngá» (confidence > 0.5): {suspicious_frames}/{len(all_confs)}")
    print(f"   - Confidence trung bÃ¬nh: {avg_confidence:.3f}")
    print(f"   - Confidence cao nháº¥t: {max_confidence:.3f}")
    print(f"   - Tá»‰ lá»‡ frames nghi ngá»: {suspicious_frames/len(all_confs):.1%}")
    
    # PhÃ¢n tÃ­ch káº¿t luáº­n
    print(f"\nğŸ¯ Káº¾T LUáº¬N CHUYÃŠN SÃ‚U:")
    if result['prediction'] == 'FAKE':
        if result['confidence'] > 0.8:
            print("   ğŸš¨ VIDEO CÃ“ Dáº¤U HIá»†U DEEPFAKE Ráº¤T RÃ• RÃ€NG")
            print("   - Nhiá»u frames cÃ³ confidence cao")
            print("   - AI phÃ¡t hiá»‡n cÃ¡c báº¥t thÆ°á»ng nháº¥t quÃ¡n")
        elif result['confidence'] > 0.6:
            print("   âš ï¸ VIDEO CÃ“ KHáº¢ NÄ‚NG CAO LÃ€ DEEPFAKE")
            print("   - Äa sá»‘ frames thá»ƒ hiá»‡n dáº¥u hiá»‡u báº¥t thÆ°á»ng")
        else:
            print("   ğŸ¤” VIDEO NGHI NGá»œ DEEPFAKE")
            print("   - Má»™t sá»‘ frames cÃ³ dáº¥u hiá»‡u báº¥t thÆ°á»ng")
    else:
        if result['confidence'] > 0.8:
            print("   âœ… VIDEO CÃ“ Váºº HOÃ€N TOÃ€N Tá»° NHIÃŠN")
            print("   - CÃ¡c frames Ä‘á»u thá»ƒ hiá»‡n Ä‘áº·c Ä‘iá»ƒm tá»± nhiÃªn")
        else:
            print("   ğŸ‘ VIDEO CÃ“ KHáº¢ NÄ‚NG CAO LÃ€ THáº¬T")
            print("   - Háº§u háº¿t frames khÃ´ng cÃ³ dáº¥u hiá»‡u báº¥t thÆ°á»ng")

def main():
    parser = argparse.ArgumentParser(description='Deepfake Detection - PhiÃªn báº£n nÃ¢ng cao')
    parser.add_argument('--video', type=str, required=True, help='ÄÆ°á»ng dáº«n video cáº§n kiá»ƒm tra')
    parser.add_argument('--model', type=str, default='best_deepfake_model_dfd.pth', help='ÄÆ°á»ng dáº«n model')
    parser.add_argument('--device', type=str, default='auto', help='Device: auto, cuda, hoáº·c cpu')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.video):
        print(f"âŒ Video khÃ´ng tá»“n táº¡i: {args.video}")
        return
    
    try:
        model, device = load_trained_model(args.model, args.device)
    except Exception as e:
        print(f"âŒ Lá»—i khi load model: {e}")
        return
    
    face_detector = FaceDetector()
    video_processor = VideoProcessor(face_detector)
    
    # Sá»­ dá»¥ng hÃ m phÃ¢n tÃ­ch chi tiáº¿t má»›i
    result = video_processor.predict_video_detailed(args.video, model, device)
    
    # Hiá»ƒn thá»‹ káº¿t quáº£ nÃ¢ng cao
    display_advanced_result(args.video, result)

if __name__ == "__main__":
    main()
#rá»“i Ä‘áº¥y bÃ¢y h sá»­a code Ä‘Ãª :) 
def predict_deepfake(video_path, model_path='best_deepfake_model_dfd.pth', device='auto'):
    """
    HÃ m dá»± Ä‘oÃ¡n Ä‘á»ƒ gá»i tá»« Flask
    """
    try:
        if not os.path.exists(video_path):
            return {"error": "Video file not found"}

        # Load model
        model, device = load_trained_model(model_path, device)
        face_detector = FaceDetector()
        video_processor = VideoProcessor(face_detector)

        # Dá»± Ä‘oÃ¡n (dÃ¹ng phÆ°Æ¡ng thá»©c chi tiáº¿t)
        result = video_processor.predict_video_detailed(video_path, model, device)
        return result

    except Exception as e:
        return {"error": f"Prediction error: {str(e)}"}
