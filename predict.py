# predict.py
import os
# predict.py
import os
import argparse
import cv2
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
from utils.model_loader import load_trained_model
from utils.face_detector import FaceDetector
from utils.video_processor import VideoProcessor

def create_confidence_timeline(time_confidence_data, overall_prediction):
    """T·∫°o bi·ªÉu ƒë·ªì confidence theo th·ªùi gian"""
    plt.figure(figsize=(12, 4))
    
    times = [data['time_sec'] for data in time_confidence_data]
    confidences = [data['confidence'] for data in time_confidence_data]
    
    plt.plot(times, confidences, 'b-', alpha=0.7, linewidth=2, label='Confidence FAKE')
    plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Ng∆∞·ª°ng FAKE/REAL')
    plt.fill_between(times, confidences, 0.5, where=np.array(confidences)>0.5, 
                     alpha=0.3, color='red', label='V√πng nghi ng·ªù FAKE')
    plt.fill_between(times, confidences, 0.5, where=np.array(confidences)<=0.5, 
                     alpha=0.3, color='green', label='V√πng an to√†n')
    
    plt.xlabel('Th·ªùi gian (gi√¢y)')
    plt.ylabel('Confidence FAKE')
    plt.title('BI·ªÇU ƒê·ªí CONFIDENCE THEO TH·ªúI GIAN')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)
    
    # Th√™m c√°c ƒëi·ªÉm ƒë√°nh d·∫•u cho c√°c frame nghi ng·ªù nh·∫•t
    top_suspicious = sorted(zip(times, confidences), key=lambda x: x[1], reverse=True)[:3]
    for time, conf in top_suspicious:
        plt.plot(time, conf, 'ro', markersize=8)
        plt.annotate(f'{conf:.2f}', (time, conf), xytext=(5, 5), 
                    textcoords='offset points', fontweight='bold')
    
    return plt

def display_advanced_result(video_path, result):
    """Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n t√≠ch n√¢ng cao"""
    color = 'red' if result['prediction'] == 'FAKE' else 'green'
    emoji = '‚ùå' if result['prediction'] == 'FAKE' else '‚úÖ'
    
    print(f"\n{'='*80}")
    print(f"{emoji} PH√ÇN T√çCH DEEPFAKE CHI TI·∫æT {emoji}")
    print(f"{'='*80}")
    print(f"üìπ Video: {os.path.basename(video_path)}")
    print(f"üéØ K·∫æT QU·∫¢: {result['prediction']}")
    print(f"üìä ƒê·ªô tin c·∫≠y t·ªïng: {result['confidence']:.1%}")
    print(f"üî¢ X√°c su·∫•t FAKE: {result['probability']:.4f}")
    print(f"üë§ S·ªë frames ph√¢n t√≠ch: {result['num_faces']}")
    
    # Hi·ªÉn th·ªã c√°c frame nghi ng·ªù nh·∫•t
    if result['frame_analysis']:
        print(f"\nüîç {len(result['frame_analysis'])} FRAME NGHI NG·ªú NH·∫§T:")
        
        # T·∫°o subplot cho c√°c frame nghi ng·ªù
        num_frames = len(result['frame_analysis'])
        fig, axes = plt.subplots(2, num_frames, figsize=(20, 8))
        
        if num_frames == 1:
            axes = axes.reshape(2, 1)
        
        for i, frame_info in enumerate(result['frame_analysis']):
            # H√†ng 1: ·∫¢nh g·ªëc v·ªõi bounding box
            face_rgb = cv2.cvtColor(frame_info['face_image'], cv2.COLOR_BGR2RGB)
            axes[0, i].imshow(face_rgb)
            axes[0, i].set_title(f'Frame {frame_info["frame_index"]}\nConf: {frame_info["confidence"]:.3f}', 
                               color='red' if frame_info['is_suspicious'] else 'green',
                               fontweight='bold')
            axes[0, i].axis('off')
            
            # H√†ng 2: Heatmap overlay
            if 'heatmap_overlay' in frame_info:
                heatmap_rgb = cv2.cvtColor(frame_info['heatmap_overlay'], cv2.COLOR_BGR2RGB)
                axes[1, i].imshow(heatmap_rgb)
                axes[1, i].set_title('Heatmap\n(V√πng AI ch√∫ √Ω)', fontsize=10)
                axes[1, i].axis('off')
            
            # Th√™m bounding box m√†u theo m·ª©c ƒë·ªô nghi ng·ªù
            for spine in axes[0, i].spines.values():
                spine.set_edgecolor('red' if frame_info['is_suspicious'] else 'green')
                spine.set_linewidth(3)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.85)
        plt.suptitle('C√ÅC FRAME NGHI NG·ªú NH·∫§T V√Ä HEATMAP PH√ÇN T√çCH', 
                    fontsize=14, color=color, fontweight='bold')
        plt.show()
    
    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì timeline
    if result['time_confidence_data']:
        timeline_plot = create_confidence_timeline(result['time_confidence_data'], result['prediction'])
        timeline_plot.show()
    
    # Th·ªëng k√™ chi ti·∫øt
    print(f"\nüìà TH·ªêNG K√ä PH√ÇN T√çCH:")
    all_confs = result['all_frame_confidences']
    suspicious_frames = sum(1 for conf in all_confs if conf > 0.5)
    avg_confidence = np.mean(all_confs)
    max_confidence = max(all_confs)
    
    print(f"   - Frames nghi ng·ªù (confidence > 0.5): {suspicious_frames}/{len(all_confs)}")
    print(f"   - Confidence trung b√¨nh: {avg_confidence:.3f}")
    print(f"   - Confidence cao nh·∫•t: {max_confidence:.3f}")
    print(f"   - T·ªâ l·ªá frames nghi ng·ªù: {suspicious_frames/len(all_confs):.1%}")
    
    # Ph√¢n t√≠ch k·∫øt lu·∫≠n
    print(f"\nüéØ K·∫æT LU·∫¨N CHUY√äN S√ÇU:")
    if result['prediction'] == 'FAKE':
        if result['confidence'] > 0.8:
            print("   üö® VIDEO C√ì D·∫§U HI·ªÜU DEEPFAKE R·∫§T R√ï R√ÄNG")
            print("   - Nhi·ªÅu frames c√≥ confidence cao")
            print("   - AI ph√°t hi·ªán c√°c b·∫•t th∆∞·ªùng nh·∫•t qu√°n")
        elif result['confidence'] > 0.6:
            print("   ‚ö†Ô∏è VIDEO C√ì KH·∫¢ NƒÇNG CAO L√Ä DEEPFAKE")
            print("   - ƒêa s·ªë frames th·ªÉ hi·ªán d·∫•u hi·ªáu b·∫•t th∆∞·ªùng")
        else:
            print("   ü§î VIDEO NGHI NG·ªú DEEPFAKE")
            print("   - M·ªôt s·ªë frames c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng")
    else:
        if result['confidence'] > 0.8:
            print("   ‚úÖ VIDEO C√ì V·∫∫ HO√ÄN TO√ÄN T·ª∞ NHI√äN")
            print("   - C√°c frames ƒë·ªÅu th·ªÉ hi·ªán ƒë·∫∑c ƒëi·ªÉm t·ª± nhi√™n")
        else:
            print("   üëç VIDEO C√ì KH·∫¢ NƒÇNG CAO L√Ä TH·∫¨T")
            print("   - H·∫ßu h·∫øt frames kh√¥ng c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng")

def main():
    parser = argparse.ArgumentParser(description='Deepfake Detection - Phi√™n b·∫£n n√¢ng cao')
    parser.add_argument('--video', type=str, required=True, help='ƒê∆∞·ªùng d·∫´n video c·∫ßn ki·ªÉm tra')
    parser.add_argument('--model', type=str, default='best_deepfake_model_dfd.pth', help='ƒê∆∞·ªùng d·∫´n model')
    parser.add_argument('--device', type=str, default='auto', help='Device: auto, cuda, ho·∫∑c cpu')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.video):
        print(f"‚ùå Video kh√¥ng t·ªìn t·∫°i: {args.video}")
        return
    
    try:
        model, device = load_trained_model(args.model, args.device)
    except Exception as e:
        print(f"‚ùå L·ªói khi load model: {e}")
        return
    
    face_detector = FaceDetector()
    video_processor = VideoProcessor(face_detector)
    
    # S·ª≠ d·ª•ng h√†m ph√¢n t√≠ch chi ti·∫øt m·ªõi
    result = video_processor.predict_video_detailed(args.video, model, device)
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ n√¢ng cao
    display_advanced_result(args.video, result)

if __name__ == "__main__":
    main()

# PostgreSQL connection (Render DATABASE_URL)
DB_URL = os.environ.get("DATABASE_URL")
conn = psycopg2.connect(DB_URL, sslmode="require")

def predict_deepfake(video_path):
    result = process_video_for_api(video_path, model, device)

    # L∆∞u k·∫øt qu·∫£ v√†o DB
    try:
        with conn.cursor() as cur:
            cur.execute(
                "INSERT INTO results (filename, prediction, probability) VALUES (%s, %s, %s)",
                (os.path.basename(video_path), result['prediction'], result['probability'])
            )
            conn.commit()
    except Exception as e:
        print(f"‚ùå L·ªói l∆∞u DB: {e}")

    return result
