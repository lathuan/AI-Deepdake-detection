# predict.py
import os
import argparse
import cv2
import matplotlib.pyplot as plt
from utils.model_loader import load_trained_model
from utils.face_detector import FaceDetector
from utils.video_processor import VideoProcessor

def display_result(video_path, result):
    """Hiá»ƒn thá»‹ káº¿t quáº£ dá»± Ä‘oÃ¡n"""
    color = 'red' if result['prediction'] == 'FAKE' else 'green'
    emoji = 'âŒ' if result['prediction'] == 'FAKE' else 'âœ…'
    
    print(f"\n{'='*60}")
    print(f"{emoji} Káº¾T QUáº¢ Dá»° ÄOÃN DEEPFAKE {emoji}")
    print(f"{'='*60}")
    print(f"ðŸ“¹ Video: {os.path.basename(video_path)}")
    print(f"ðŸ” Káº¿t quáº£: {result['prediction']}")
    print(f"ðŸ“Š Äá»™ tin cáº­y: {result['confidence']:.4f}")
    print(f"ðŸŽ¯ XÃ¡c suáº¥t FAKE: {result['probability']:.4f}")
    print(f"ðŸ‘¤ Sá»‘ khuÃ´n máº·t phÃ¢n tÃ­ch: {result['num_faces']}")
    
    # Hiá»ƒn thá»‹ khuÃ´n máº·t náº¿u cÃ³
    if 'faces_sample' in result and len(result['faces_sample']) > 0:
        print(f"\nðŸ–¼ï¸  Máº«u khuÃ´n máº·t trÃ­ch xuáº¥t:")
        
        fig, axes = plt.subplots(1, len(result['faces_sample']), figsize=(12, 3))
        if len(result['faces_sample']) == 1:
            axes = [axes]
            
        for i, (face, ax) in enumerate(zip(result['faces_sample'], axes)):
            face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)
            ax.imshow(face_rgb)
            ax.set_title(f'Frame {i+1}')
            ax.axis('off')
        
        plt.tight_layout()
        plt.show()

def main():
    parser = argparse.ArgumentParser(description='Deepfake Detection')
    parser.add_argument('--video', type=str, required=True, help='ÄÆ°á»ng dáº«n video cáº§n kiá»ƒm tra')
    parser.add_argument('--model', type=str, default='past/best_deepfake_model_dfd.pth', help='ÄÆ°á»ng dáº«n model')
    parser.add_argument('--device', type=str, default='auto', help='Device: auto, cuda, hoáº·c cpu')
    
    args = parser.parse_args()
    
    # Kiá»ƒm tra file video
    if not os.path.exists(args.video):
        print(f"âŒ Video khÃ´ng tá»“n táº¡i: {args.video}")
        return
    
    # Load model
    try:
        model, device = load_trained_model(args.model, args.device)
    except Exception as e:
        print(f"âŒ Lá»—i khi load model: {e}")
        return
    
    # Khá»Ÿi táº¡o face detector vÃ  video processor
    face_detector = FaceDetector(model_path='yolov8l-face-lindevs.pt')
    video_processor = VideoProcessor(face_detector)
    
    # Dá»± Ä‘oÃ¡n
    result = video_processor.predict_video(args.video, model, device)
    
    # Hiá»ƒn thá»‹ káº¿t quáº£
    display_result(args.video, result)

# ThÃªm vÃ o cuá»‘i predict.py (trÆ°á»›c if __name__ == "__main__")

def predict_deepfake(video_path, model_path='model/best_deepfake_model_dfd.pth', device='auto'):
    """
    HÃ m dá»± Ä‘oÃ¡n deepfake cho Flask app
    """
    try:
        # Kiá»ƒm tra file video
        if not os.path.exists(video_path):
            return {"error": "Video file not found"}
        
        # Load model
        model, device = load_trained_model(model_path, device)
        
        # Khá»Ÿi táº¡o face detector vÃ  video processor
        face_detector = FaceDetector(model_path='yolov8l-face-lindevs.pt')
        video_processor = VideoProcessor(face_detector)
        
        # Dá»± Ä‘oÃ¡n
        result = video_processor.predict_video(video_path, model, device)
        
        return result
        
    except Exception as e:
        return {"error": f"Prediction error: {str(e)}"}

if __name__ == "__main__":
    main()
import os
from utils.model_loader import load_trained_model
from utils.face_detector import FaceDetector
from utils.video_processor import VideoProcessor
import cv2
import base64

def encode_face_to_base64(face):
    _, buffer = cv2.imencode('.jpg', face)
    return base64.b64encode(buffer.tobytes()).decode('utf-8')

def predict_deepfake(video_path, model_path='model/best_deepfake_model_dfd.pth', device='auto'):
    try:
        if not os.path.exists(video_path):
            return {"error": "Video file not found"}

        model, device = load_trained_model(model_path, device)
        face_detector = FaceDetector(model_path='yolov8l-face-lindevs.pt')
        video_processor = VideoProcessor(face_detector)

        result = video_processor.predict_video(video_path, model, device)

        # Encode faces sample sang base64
        if 'faces_sample' in result and len(result['faces_sample']) > 0:
            result['faces_sample'] = [encode_face_to_base64(face) for face in result['faces_sample']]

        return result
    except Exception as e:
        return {"error": f"Prediction error: {str(e)}"}
