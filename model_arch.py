# model_arch.py - PHIÃŠN Báº¢N Cáº¢I THIá»†N (THÃŠM DROPOUT & Lá»šPMá»šI)

import tensorflow as tf
from tensorflow.keras.layers import (Input, GlobalAveragePooling2D, Dense, 
                                     Concatenate, BatchNormalization, Dropout)
from tensorflow.keras.applications import Xception, ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import Precision, Recall, AUC


# --- HÃ€M Táº O MÃ” HÃŒNH TWO-STREAM (Cáº¢I THIá»†N) ---
def create_two_stream_model(face_input_shape, context_input_shape, dropout_stream=0.4, 
                           dropout_combined=0.3, dense_1=128, dense_2=64, dense_3=32):
    """
    Táº¡o mÃ´ hÃ¬nh two-stream vá»›i:
    - Dropout Ä‘á»ƒ trÃ¡nh overfitting
    - Lá»›p Dense trung gian thÃªm
    - Metrics: Precision, Recall, AUC
    
    Args:
        face_input_shape: Tuple (height, width, channels) cho Face stream
        context_input_shape: Tuple (height, width, channels) cho Context stream
        dropout_stream: Dropout rate sau Face/Context output
        dropout_combined: Dropout rate sau combined layers
        dense_1: Sá»‘ unit cho dense layer 1 (Face & Context output)
        dense_2: Sá»‘ unit cho dense layer 2 (combined)
        dense_3: Sá»‘ unit cho dense layer 3 (combined)
    
    Returns:
        Keras Model
    """
    
    # ===== NHÃNH 1: KHUÃ”N Máº¶T (FACE STREAM) - XCEPTION =====
    face_input = Input(shape=face_input_shape, name='face_input')
    
    # Táº£i Xception pretrained
    face_base = Xception(weights='imagenet', include_top=False, 
                        input_tensor=face_input, name='xception')
    
    # KhÃ³a toÃ n bá»™ lá»›p ban Ä‘áº§u
    for layer in face_base.layers:
        layer.trainable = False
    
    # Xá»­ lÃ½ output
    x = face_base.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(dense_1, activation='relu', name='face_dense_1')(x)
    x = Dropout(dropout_stream, name='face_dropout_1')(x)  # THÃŠM DROPOUT
    face_output = x
    
    
    # ===== NHÃNH 2: NGá»® Cáº¢NH (CONTEXT STREAM) - RESNET50 =====
    context_input = Input(shape=context_input_shape, name='context_input')
    
    # Táº£i ResNet50 pretrained
    context_base = ResNet50(weights='imagenet', include_top=False, 
                           input_tensor=context_input, name='resnet50')
    
    # KhÃ³a toÃ n bá»™ lá»›p ban Ä‘áº§u
    for layer in context_base.layers:
        layer.trainable = False
    
    # Xá»­ lÃ½ output
    y = context_base.output
    y = GlobalAveragePooling2D()(y)
    y = Dense(dense_1, activation='relu', name='context_dense_1')(y)
    y = Dropout(dropout_stream, name='context_dropout_1')(y)  # THÃŠM DROPOUT
    context_output = y
    
    
    # ===== Káº¾T Há»¢P VÃ€ PHÃ‚N LOáº I =====
    combined = Concatenate(name='concatenate')([face_output, context_output])
    combined = BatchNormalization(name='batch_norm_1')(combined)
    
    # Dense layer 1
    combined = Dense(dense_2, activation='relu', name='combined_dense_1')(combined)
    combined = Dropout(dropout_combined, name='combined_dropout_1')(combined)  # THÃŠM DROPOUT
    
    # Dense layer 2 (Lá»šP Má»šI THÃŠM VÃ€O)
    combined = Dense(dense_3, activation='relu', name='combined_dense_2')(combined)
    combined = Dropout(dropout_combined * 0.67, name='combined_dropout_2')(combined)  # DROPOUT CHA HÆ N
    
    # Output layer
    output = Dense(2, activation='softmax', name='output')(combined)
    
    # Táº¡o model
    model = Model(inputs=[face_input, context_input], outputs=output, 
                 name='TwoStreamDeepfakeDetector')
    
    return model


# --- HÃ€M COMPILE MÃ” HÃŒNH Vá»šI METRICS Cáº¢I THIá»†N ---
def compile_model(model, learning_rate, use_focal_loss=False):
    """
    Compile mÃ´ hÃ¬nh vá»›i loss, optimizer vÃ  metrics cáº£i thiá»‡n
    
    Args:
        model: Keras model
        learning_rate: Learning rate cho optimizer
        use_focal_loss: Sá»­ dá»¥ng Focal Loss (tá»‘t hÆ¡n cho imbalanced data)
                       Náº¿u False, dÃ¹ng categorical crossentropy
    
    Returns:
        Compiled model
    """
    
    if use_focal_loss:
        try:
            import tensorflow_addons as tfa
            loss_fn = tfa.losses.SigmoidFocalCrossEntropy()
            print("âœ“ DÃ¹ng Focal Loss cho imbalanced data")
        except ImportError:
            print("âš  tensorflow_addons khÃ´ng Ä‘Æ°á»£c cÃ i. Sá»­ dá»¥ng Categorical Crossentropy")
            loss_fn = tf.keras.losses.CategoricalCrossentropy()
    else:
        loss_fn = tf.keras.losses.CategoricalCrossentropy()
    
    model.compile(
        optimizer=Adam(learning_rate=learning_rate),
        loss=loss_fn,
        metrics=[
            'accuracy',
            Precision(name='precision'),  # THÃŠM PRECISION
            Recall(name='recall'),         # THÃŠM RECALL
            AUC(name='auc')               # THÃŠM AUC
        ]
    )
    
    return model


# --- HÃ€M TINH CHá»ˆNH (FINE-TUNING) - Cáº¢I THIá»†N =====
def fine_tune_two_stream_model(model, learning_rate_finetune, 
                              unfreeze_xception=50, unfreeze_resnet=50):
    """
    Fine-tune mÃ´ hÃ¬nh báº±ng cÃ¡ch má»Ÿ khÃ³a lá»›p cuá»‘i
    
    Args:
        model: Trained model
        learning_rate_finetune: Learning rate cho fine-tuning
        unfreeze_xception: Sá»‘ lá»›p cuá»‘i cá»§a Xception Ä‘á»ƒ má»Ÿ khÃ³a
        unfreeze_resnet: Sá»‘ lá»›p cuá»‘i cá»§a ResNet50 Ä‘á»ƒ má»Ÿ khÃ³a
    
    Returns:
        Model sau khi fine-tune
    """
    
    xception_base = None
    resnet_base = None
    
    # CÃ“ CHá»‚ 1: TÃ¬m báº±ng isinstance + name
    for layer in model.layers:
        if isinstance(layer, Xception) and layer.name == 'xception':
            xception_base = layer
        elif isinstance(layer, ResNet50) and layer.name == 'resnet50':
            resnet_base = layer
    
    # CÆ  CHáº¾ 2: TÃ¬m báº±ng get_layer (náº¿u cÆ¡ cháº¿ 1 tháº¥t báº¡i)
    if xception_base is None:
        try:
            xception_base = model.get_layer('xception')
        except ValueError:
            pass
    
    if resnet_base is None:
        try:
            resnet_base = model.get_layer('resnet50')
        except ValueError:
            pass
    
    # Lá»–I: KhÃ´ng tÃ¬m tháº¥y base models
    if xception_base is None or resnet_base is None:
        print("âŒ Lá»–I: KHÃ”NG THá»‚ TINH CHá»ˆNH. Tháº¥t báº¡i khi tÃ¬m lá»›p ná»n Xception/ResNet50.")
        print("âš  Sáº½ dÃ¹ng mÃ´ hÃ¬nh hiá»‡n táº¡i mÃ  khÃ´ng fine-tune")
        
        # Compile láº¡i vá»›i loss & metrics tÆ°á»ng minh
        model = compile_model(model, learning_rate_finetune)
        return model
    
    # Má» KHÃ“A CÃC Lá»šP CUá»I
    print(f"ğŸ”“ Má»Ÿ khÃ³a {unfreeze_xception} lá»›p cuá»‘i cá»§a Xception...")
    for layer in xception_base.layers[-unfreeze_xception:]:
        if not isinstance(layer, BatchNormalization):
            layer.trainable = True
    
    print(f"ğŸ”“ Má»Ÿ khÃ³a {unfreeze_resnet} lá»›p cuá»‘i cá»§a ResNet50...")
    for layer in resnet_base.layers[-unfreeze_resnet:]:
        if not isinstance(layer, BatchNormalization):
            layer.trainable = True
    
    print(f"âœ“ ÄÃ£ má»Ÿ khÃ³a {unfreeze_xception + unfreeze_resnet} lá»›p ná»n")
    
    # COMPILE Láº I Vá»šI LEARNING RATE Má»šI
    model = compile_model(model, learning_rate_finetune, use_focal_loss=False)
    
    return model


# --- HÃ€M IN Cáº¤U TRÃšC MÃ” HÃŒNH (DEBUG) ---
def print_model_summary(model, verbose=False):
    """
    In thÃ´ng tin chi tiáº¿t vá» mÃ´ hÃ¬nh
    """
    print("\n" + "="*80)
    print("ğŸ“Š THÃ”NG TIN MÃ” HÃŒNH")
    print("="*80)
    
    model.summary()
    
    if verbose:
        print("\nğŸ“‹ CHI TIáº¾T CÃC Lá»šP:")
        for i, layer in enumerate(model.layers):
            trainable = "ğŸ”“" if layer.trainable else "ğŸ”’"
            params = layer.count_params()
            print(f"  {i:2d}. {trainable} {layer.name:30s} | {layer.__class__.__name__:20s} | {params:>12,} params")
    
    print("="*80 + "\n")