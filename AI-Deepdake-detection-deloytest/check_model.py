# check_model.py
import os
import torch

def check_model_file(model_path):
    print(f"ğŸ” Kiá»ƒm tra file model: {model_path}")
    
    if not os.path.exists(model_path):
        print("âŒ File model khÃ´ng tá»“n táº¡i!")
        return False
    
    file_size = os.path.getsize(model_path) / 1024 / 1024
    print(f"ğŸ“ KÃ­ch thÆ°á»›c file: {file_size:.2f} MB")
    
    if file_size < 1:
        print("âŒ File model quÃ¡ nhá», cÃ³ thá»ƒ bá»‹ há»ng!")
        return False
    
    try:
        # Thá»­ load vá»›i cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhau
        print("ğŸ”„ Äang thá»­ load model...")
        
        # PhÆ°Æ¡ng phÃ¡p 1: Load bÃ¬nh thÆ°á»ng
        try:
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
            print("âœ… Load thÃ nh cÃ´ng vá»›i phÆ°Æ¡ng phÃ¡p 1")
            return True
        except:
            pass
        
        # PhÆ°Æ¡ng phÃ¡p 2: Load vá»›i pickle (cáº©n tháº­n)
        try:
            checkpoint = torch.load(model_path, map_location='cpu', pickle_module=__import__('pickle'))
            print("âœ… Load thÃ nh cÃ´ng vá»›i phÆ°Æ¡ng phÃ¡p 2")
            return True
        except:
            pass
            
        print("âŒ Táº¥t cáº£ phÆ°Æ¡ng phÃ¡p load Ä‘á»u tháº¥t báº¡i!")
        return False
        
    except Exception as e:
        print(f"âŒ Lá»—i khi kiá»ƒm tra model: {e}")
        return False

if __name__ == "__main__":
    check_model_file("model/best_deepfake_model_dfd.pth")