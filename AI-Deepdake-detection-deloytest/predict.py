# predict.py
import uuid
import os
import argparse
import cv2
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime
from utils.model_loader import load_trained_model
from utils.face_detector import FaceDetector
from utils.video_processor import VideoProcessor
from PIL import Image


def create_confidence_timeline(time_confidence_data,overall_prediction):
    """T·∫°o bi·ªÉu ƒë·ªì confidence theo th·ªùi gian"""
    plt.figure(figsize=(12, 4))
    
    times = [data['time_sec'] for data in time_confidence_data]
    confidences = [data['confidence'] for data in time_confidence_data]
    
    plt.plot(times, confidences, 'b-', alpha=0.7, linewidth=2, label='Confidence FAKE')
    plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Ng∆∞·ª°ng FAKE/REAL')
    plt.fill_between(times, confidences, 0.5, where=np.array(confidences)>0.5, 
                     alpha=0.3, color='red', label='V√πng nghi ng·ªù FAKE')
    plt.fill_between(times, confidences, 0.5, where=np.array(confidences)<=0.5, 
                     alpha=0.3, color='green', label='V√πng an to√†n')
    
    plt.xlabel('Th·ªùi gian (gi√¢y)')
    plt.ylabel('Confidence FAKE')
    plt.title('BI·ªÇU ƒê·ªí CONFIDENCE THEO TH·ªúI GIAN')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1)
    return plt

def predict_deepfake(video_path, model_path='best_deepfake_model_dfd.pth', device='auto'):
    """H√†m d·ª± ƒëo√°n ƒë·ªÉ g·ªçi t·ª´ Flask"""
    try:
        if not os.path.exists(video_path):
            return {"error": "Video file not found"}

        model, device = load_trained_model(model_path, device)
        face_detector = FaceDetector()
        video_processor = VideoProcessor(face_detector)

        result = video_processor.predict_video_detailed(video_path, model, device)

        # Chu·∫©n b·ªã frame + heatmap cho web
        frames_for_web = []
        if "frame_analysis" in result and result["frame_analysis"]:
            for frame_info in result["frame_analysis"]:
                face_rgb = frame_info['face_image'][..., ::-1]  # BGR->RGB
                pil_face = Image.fromarray(face_rgb)
                pil_heatmap = None
                if 'heatmap_overlay' in frame_info:
                    heatmap_rgb = frame_info['heatmap_overlay'][..., ::-1]
                    pil_heatmap = Image.fromarray(heatmap_rgb)

                frames_for_web.append({
                    "frame_index": frame_info['frame_index'],
                    "confidence": frame_info['confidence'],
                    "is_suspicious": frame_info['is_suspicious'],
                    "face_image": pil_face,
                    "heatmap_overlay": pil_heatmap
                })
        result['frames_for_web'] = frames_for_web
        return result

    except Exception as e:
        return {"error": f"Prediction error: {str(e)}"}

def display_advanced_result(video_path, result):
    """Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n t√≠ch n√¢ng cao"""
    color = 'red' if result['prediction'] == 'FAKE' else 'green'
    emoji = '‚ùå' if result['prediction'] == 'FAKE' else '‚úÖ'
    
    print(f"\n{'='*80}")
    print(f"{emoji} PH√ÇN T√çCH DEEPFAKE CHI TI·∫æT {emoji}")
    print(f"{'='*80}")
    print(f"üìπ Video: {os.path.basename(video_path)}")
    print(f"üéØ K·∫æT QU·∫¢: {result['prediction']}")
    print(f"üìä ƒê·ªô tin c·∫≠y t·ªïng: {result['confidence']:.1%}")
    print(f"üî¢ X√°c su·∫•t FAKE: {result['probability']:.4f}")
    print(f"üë§ S·ªë frames ph√¢n t√≠ch: {result['num_faces']}")
    
    # Hi·ªÉn th·ªã c√°c frame nghi ng·ªù nh·∫•t
    if result['frame_analysis']:
        print(f"\nüîç {len(result['frame_analysis'])} FRAME NGHI NG·ªú NH·∫§T:")
        
        # T·∫°o subplot cho c√°c frame nghi ng·ªù
        num_frames = len(result['frame_analysis'])
        fig, axes = plt.subplots(2, num_frames, figsize=(20, 8))
        
        if num_frames == 1:
            axes = axes.reshape(2, 1)
        
        for i, frame_info in enumerate(result['frame_analysis']):
            # H√†ng 1: ·∫¢nh g·ªëc v·ªõi bounding box
            face_rgb = cv2.cvtColor(frame_info['face_image'], cv2.COLOR_BGR2RGB)
            axes[0, i].imshow(face_rgb)
            axes[0, i].set_title(f'Frame {frame_info["frame_index"]}\nConf: {frame_info["confidence"]:.3f}', 
                               color='red' if frame_info['is_suspicious'] else 'green',
                               fontweight='bold')
            axes[0, i].axis('off')
            
            # H√†ng 2: Heatmap overlay
            if 'heatmap_overlay' in frame_info:
                heatmap_rgb = cv2.cvtColor(frame_info['heatmap_overlay'], cv2.COLOR_BGR2RGB)
                axes[1, i].imshow(heatmap_rgb)
                axes[1, i].set_title('Heatmap\n(V√πng AI ch√∫ √Ω)', fontsize=10)
                axes[1, i].axis('off')
            
            # Th√™m bounding box m√†u theo m·ª©c ƒë·ªô nghi ng·ªù
            for spine in axes[0, i].spines.values():
                spine.set_edgecolor('red' if frame_info['is_suspicious'] else 'green')
                spine.set_linewidth(3)
        
        plt.tight_layout()
        plt.subplots_adjust(top=0.85)
        plt.suptitle('C√ÅC FRAME NGHI NG·ªú NH·∫§T V√Ä HEATMAP PH√ÇN T√çCH', 
                    fontsize=14, color=color, fontweight='bold')
        plt.show()
    
    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì timeline
    if result['time_confidence_data']:
        timeline_plot = create_confidence_timeline(result['time_confidence_data'], result['prediction'])
        timeline_plot.show()
    
    # Th·ªëng k√™ chi ti·∫øt
    print(f"\nüìà TH·ªêNG K√ä PH√ÇN T√çCH:")
    all_confs = result['all_frame_confidences']
    suspicious_frames = sum(1 for conf in all_confs if conf > 0.5)
    avg_confidence = np.mean(all_confs)
    max_confidence = max(all_confs)
    
    print(f"   - Frames nghi ng·ªù (confidence > 0.5): {suspicious_frames}/{len(all_confs)}")
    print(f"   - Confidence trung b√¨nh: {avg_confidence:.3f}")
    print(f"   - Confidence cao nh·∫•t: {max_confidence:.3f}")
    print(f"   - T·ªâ l·ªá frames nghi ng·ªù: {suspicious_frames/len(all_confs):.1%}")
    
    # Ph√¢n t√≠ch k·∫øt lu·∫≠n
    print(f"\nüéØ K·∫æT LU·∫¨N CHUY√äN S√ÇU:")
    if result['prediction'] == 'FAKE':
        if result['confidence'] > 0.8:
            print("   üö® VIDEO C√ì D·∫§U HI·ªÜU DEEPFAKE R·∫§T R√ï R√ÄNG")
            print("   - Nhi·ªÅu frames c√≥ confidence cao")
            print("   - AI ph√°t hi·ªán c√°c b·∫•t th∆∞·ªùng nh·∫•t qu√°n")
        elif result['confidence'] > 0.6:
            print("   ‚ö†Ô∏è VIDEO C√ì KH·∫¢ NƒÇNG CAO L√Ä DEEPFAKE")
            print("   - ƒêa s·ªë frames th·ªÉ hi·ªán d·∫•u hi·ªáu b·∫•t th∆∞·ªùng")
        else:
            print("   ü§î VIDEO NGHI NG·ªú DEEPFAKE")
            print("   - M·ªôt s·ªë frames c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng")
    else:
        if result['confidence'] > 0.8:
            print("   ‚úÖ VIDEO C√ì V·∫∫ HO√ÄN TO√ÄN T·ª∞ NHI√äN")
            print("   - C√°c frames ƒë·ªÅu th·ªÉ hi·ªán ƒë·∫∑c ƒëi·ªÉm t·ª± nhi√™n")
        else:
            print("   üëç VIDEO C√ì KH·∫¢ NƒÇNG CAO L√Ä TH·∫¨T")
            print("   - H·∫ßu h·∫øt frames kh√¥ng c√≥ d·∫•u hi·ªáu b·∫•t th∆∞·ªùng")

def main():
    parser = argparse.ArgumentParser(description='Deepfake Detection - Phi√™n b·∫£n n√¢ng cao')
    parser.add_argument('--video', type=str, required=True, help='ƒê∆∞·ªùng d·∫´n video c·∫ßn ki·ªÉm tra')
    parser.add_argument('--model', type=str, default='best_deepfake_model_dfd.pth', help='ƒê∆∞·ªùng d·∫´n model')
    parser.add_argument('--device', type=str, default='auto', help='Device: auto, cuda, ho·∫∑c cpu')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.video):
        print(f"‚ùå Video kh√¥ng t·ªìn t·∫°i: {args.video}")
        return
    
    try:
        model, device = load_trained_model(args.model, args.device)
    except Exception as e:
        print(f"‚ùå L·ªói khi load model: {e}")
        return
    
    face_detector = FaceDetector()
    video_processor = VideoProcessor(face_detector)
    
    # S·ª≠ d·ª•ng h√†m ph√¢n t√≠ch chi ti·∫øt m·ªõi
    result = video_processor.predict_video_detailed(args.video, model, device)
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£ n√¢ng cao
    display_advanced_result(args.video, result)

if __name__ == "__main__":
    main()
#r·ªìi ƒë·∫•y b√¢y h s·ª≠a code ƒë√™ :) 
def predict_deepfake(video_path, model_path='best_deepfake_model_dfd.pth', device='auto'):
    """
    H√†m d·ª± ƒëo√°n ƒë·ªÉ g·ªçi t·ª´ Flask
    """
    try:
        if not os.path.exists(video_path):
            return {"error": "Video file not found"}

        # Load model
        model, device = load_trained_model(model_path, device)
        face_detector = FaceDetector()
        video_processor = VideoProcessor(face_detector)

        # D·ª± ƒëo√°n (d√πng ph∆∞∆°ng th·ª©c chi ti·∫øt)
        result = video_processor.predict_video_detailed(video_path, model, device)

        # -------- TH√äM L·∫†I PH·∫¶N frames_for_web B·ªä THI·∫æU --------
        frames_for_web = []
        if "frame_analysis" in result and result["frame_analysis"]:
            for frame_info in result["frame_analysis"]:

                # FACE
                face_bgr = frame_info.get("face_image")
                if face_bgr is not None:
                    # B·∫£o ƒë·∫£m ƒë√∫ng shape tr∆∞·ªõc khi chuy·ªÉn
                    face_rgb = face_bgr[..., ::-1]   # BGR -> RGB
                    pil_face = Image.fromarray(face_rgb)
                else:
                    pil_face = None

                # HEATMAP
                pil_heatmap = None
                if "heatmap_overlay" in frame_info and frame_info["heatmap_overlay"] is not None:
                    heatmap_bgr = frame_info["heatmap_overlay"]
                    heatmap_rgb = heatmap_bgr[..., ::-1]
                    pil_heatmap = Image.fromarray(heatmap_rgb)

                frames_for_web.append({
                    "frame_index": frame_info.get("frame_index"),
                    "confidence": frame_info.get("confidence"),
                    "is_suspicious": frame_info.get("is_suspicious"),
                    "face_image": pil_face,
                    "heatmap_overlay": pil_heatmap
                })

        result["frames_for_web"] = frames_for_web
        # --------------------------------------------------------

        return result

    except Exception as e:
        return {"error": f"Prediction error: {str(e)}"}